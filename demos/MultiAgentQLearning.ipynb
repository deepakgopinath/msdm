{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from msdm.domains.gridgame.tabulargridgame import TabularGridGame\n",
    "from msdm.domains.gridworld.mdp import GridWorld\n",
    "from msdm.algorithms.multiagentqlearning import TabularMultiagentQLearner\n",
    "from msdm.algorithms.friendfoeq import TabularFriendFoeQLearner\n",
    "from msdm.algorithms.correlatedq import TabularCorrelatedQLearner\n",
    "from msdm.algorithms.nashq import TabularNashQLearner\n",
    "from msdm.core.problemclasses.stochasticgame.policy.tabularpolicy import SingleAgentPolicy\n",
    "from msdm.core.assignment.assignmentmap import AssignmentMap\n",
    "import msdm\n",
    "import numpy as np\n",
    "import importlib\n",
    "import itertools\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_player = \"\"\"\n",
    "# # # # #\n",
    "# . G . # \n",
    "# . . . #\n",
    "# A0.~ . A1.~ #\n",
    "# # # # #\n",
    "\"\"\"\n",
    "gg = TabularGridGame(two_player,agent_symbols=(\"A0\",\"A1\"),goal_symbols=((\"G\",(\"A0\",\"A1\")),),step_cost=-1,collision_cost=-5,goal_reward=100)\n",
    "gg.state_list\n",
    "print(\"State list generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = AssignmentMap()\n",
    "for state in gg.state_list:\n",
    "    actions = list(gg.joint_actions(state)[\"A1\"])\n",
    "    random_policy[state] = AssignmentMap()\n",
    "    for action in actions:\n",
    "        random_policy[state][action] = 1.0/len(actions)\n",
    "random_policy = SingleAgentPolicy(\"A1\",gg,random_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agents = [\"A0\",\"A1\"]\n",
    "learning_agents = [\"A0\",\"A1\"]\n",
    "friends = {\"A1\":[],\"A0\":[]}\n",
    "foes = {\"A1\":[\"A0\"],\"A0\":[\"A1\"]}\n",
    "# other_policies = {\"A0\":random_policy}\n",
    "other_policies = {}\n",
    "params = {\"num_episodes\":2000,\"epsilon\":.01,\"epsilon_decay\":1.0,\"discount_rate\":.99,\n",
    "          \"learning_rate\":0.01,\"show_progress\":True,\"default_q_value\":1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_learner = TabularMultiagentQLearner(learning_agents,other_policies,all_actions=True,alg_name=\"Q-Learning\",**params)\n",
    "ffq_learner = TabularFriendFoeQLearner(learning_agents,friends,foes,other_policies,alg_name=\"FFQ-Learning\",**params)\n",
    "libertarian_q_learner = TabularCorrelatedQLearner(learning_agents,other_policies,objective_func=\"Libertarian\",alg_name=\"Libertarian CEQ\",**params)\n",
    "utilitarian_q_learner = TabularCorrelatedQLearner(learning_agents,other_policies,objective_func=\"Utilitarian\",alg_name=\"Utilitarian CEQ\",**params)\n",
    "republican_q_learner = TabularCorrelatedQLearner(learning_agents,other_policies,objective_func=\"Republican\",alg_name=\"Republican CEQ\",**params)\n",
    "egalitarian_q_learner = TabularCorrelatedQLearner(learning_agents,other_policies,objective_func=\"Egalitarian\",alg_name=\"Egalitarian CEQ\",**params)\n",
    "nash_q_learner = TabularNashQLearner(learning_agents,other_policies,alg_name=\"Nash-Q Learning\",**params)\n",
    "algorithms = [q_learner,ffq_learner,utilitarian_q_learner,republican_q_learner,egalitarian_q_learner,libertarian_q_learner,nash_q_learner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "example_trajectories = []\n",
    "for alg in algorithms:\n",
    "    res = alg.train_on(gg)\n",
    "    results.append(res)\n",
    "    trajectory = res.pi.run_on(gg,maxSteps=10)\n",
    "    example_trajectories.append(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msdm.domains.gridgame.policyviztools import positionMapping, positionActionMapping, weightMapping \n",
    "for k,alg in enumerate(algorithms): \n",
    "    fig,axes = plt.subplots(1,len(all_agents),figsize=(20,10))\n",
    "    fig.suptitle(alg.alg_name)\n",
    "    for i,agent_name in enumerate(all_agents):\n",
    "        plotter = gg.plot(ax=axes[i])\n",
    "        plotter.title(agent_name + \" Values\")\n",
    "        q_matrix = results[k].pi.single_agent_policies[agent_name].q_matrix\n",
    "        occupancy_matrix = results[k].pi.occupancy_matrix\n",
    "        occupancy_matrix.fill(1.0/len(occupancy_matrix[0]))\n",
    "        initial_state = gg.initial_state_dist().sample()\n",
    "        initial_index = gg.state_list.index(initial_state)\n",
    "        plotter.plot_state_map(positionMapping(results[k].pi,agent_name,q_matrix,occupancy_matrix,initial_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animations = []\n",
    "for k,alg in enumerate(algorithms):\n",
    "    fig, axes = plt.subplots(1,1,figsize=(20,10))\n",
    "    fig.suptitle(alg.alg_name)\n",
    "    trajectory = results[k].pi.run_on(gg,maxSteps=10)\n",
    "    animator = gg.animate(figure=fig,ax=axes)\n",
    "    animation = animator.animate_trajectory(trajectory)\n",
    "    animations.append(animation)\n",
    "display.display(*[display.HTML(animation.to_jshtml()) for animation in animations])\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
